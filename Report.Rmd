---
title: "The rminer package for regression"
author: Gabriele Venturato
date: 4 February 2019
output:
  pdf_document: default
bibliography: bibliography.bibtex
nocite: |
  @Cor10, @trevor2009elements,  @witten2016data,@cutler2013trees
abstract: |
  The aim of this work is to have an insight into the *rminer* package for regression analysis. Starting from a brief theoretical introduction, towards the description of the main functions of the package, and concluding with a simple case study to show how the package can be used.
---


# Introduction
## Regression
Regression is the problem of learning a *functional relationship* between variables using a dataset where the specific functional form learned depends on the choice of the model (it can be linear or not). The parameters of the function are learned using the *explanatory variables (features)* into the training set, and then performance are evaluates testing the model on the test set. The aim of a regression model --- as opposed to a classification model --- is to perform a *numeric prediction* based on the features in input.

## Linear Regression
If the data about the response $Y$ and the *p* regressors $X_1,\dots,X_p$ are available, the **multiple linear regression** model is defined as (the simple linear regression model can be obtained with $p=1$):

$$y_i = \beta_0 + \beta_1 x_{i1} + \dots + \beta_p x_{ip} + \epsilon_i$$

It's assumed that the error term is normally distributed with mean zero and variance $\sigma^2$, namely $\epsilon_i \sim N(0,\sigma^2)$, and that errors of different units are independent. From this assumption, given the predictors (which are taken as fixed), also the observations $Y_i$ are normally distributed with constant variance $\sigma^2$.

This model can be expressed also in matrix form as follows:

$$y = X\beta + \epsilon$$

where $y$ and $\epsilon$ are columns vectors of dimension $n$, $\beta$ is a column vector of *unknown* parameters with dimension $p+1$, and $X$ is a matrix of dimension $n \times (p+1)$.

In this form the estimation for the model parameters can be obtained with the *leas squared method* that corresponds to the MLE:

$$\hat\beta = (X^TX)^{-1}X^Ty$$

and so with $\hat\beta$ its easy to esimate the mean vector $\mu = X\beta$ of the response vector $Y$, which corresponds to the *fitted values*:

$$\hat{y} = \hat\mu = X\hat\beta = X(X^TX)^{-1}X^Ty$$

## Random Forest
Random Forest models are based on *Classification and Regression Trees* (CART), which are models commonly used in data mining with the objective of creating a tree-shpaed model that predicts the value of a dependent variable.

The tree-shaped form is given by construction ``growing the tree'': given $d$ features (explanatory variables), the procedure to build the regression tree is, for each node, to select a feature and perform a split based on the minimization of the residual sum of squares.

$$ RSS = \sum_{left}(y_i - \bar{y_L})^2 + \sum_{right}(y_i - \bar{y_R})^2$$

Where $\bar{y_L}$ and $\bar{y_R}$ are the means of the left and right node respectively. The value chosen for splitting is the one that minimizes RSS, and than it proceeds recursivly until leaves are reached. The stop criteria to define leaves can be stated as: stop when a region have less than $k$ values in it (with $k \ge 1$).

They have some advantages over traditional statistical methods because: they don't do any formal distribution assumption, they can automatically fit non-linear interactions, and they handle missing values with surrogate variables.

Morover, random forest are based on this idea, and they use a ``bag'' of these trees. They are models that have an higher accuracy, they are more stable, and they are less sensitive to overfitting. These advantages are compesated by the increased complexity. They are anyway speed in learning, but slower in prediction.

A random forest can be built with the repetition of two phases:

* take a bootstrap sample $D_i$ from the data $D$
* fit a classification or regression tree on $D_i$ set
    + for every node choose *randomly* $m$ features out of $M$ and grow the tree only on those features
    

all the trees created are at the end combined --- in case of regression --- by averaging.

# The rminer package
The goal of this package is to facilitate the use of data mining algorithms for classification and regression. It offers a short and coherent set of functions in order to easily develop a project, letting the user to follow in particular three CRISP-DM stages: *data preparation*, *modeling* and *evaluation*.

The package can be installed with:
```r
install.packages("rminer")
```

And loaded with:
```{r}
library(rminer)
```

As usual, a complete list of all functions available can be found in the documentation of the package:
```r
help(package=rminer)
```

For the purpose of this work instead of reporting what can be found easily --- and with more details --- inside the documentation, I preferred to report a brief list of the function organized by their purpose, in order to quickly move through the practical example that is more useful to show the package capabilites.

## Data Preparation
First of all, for the data preparation phase, after having loaded the dataset, the functions that can be used are mainly:

* \texttt{delevels(x, levels, label = NULL)} -- reduce or replace factor *x* with *levels*, with an optional new *label*;
* \texttt{imputation(imethod = "value", D, Attribute = NULL, Missing = NA, Value = 1)} -- perform imputation to remove missing values from dataset *D* and from a specific attribute, with the value specified.
* \texttt{CaseSeries} -- create a data.frame from a time series (vector) using a sliding window. This function is not used in this work and its behavior can be further analized in official documentation.

## Modeling
When the dataset is ready is possible to proceed with the model definition. For this phase three functions are important:

* \texttt{holdout(y, ratio = 2/3, mode = "stratified", \dots)} -- it computes indexes for holdout data split into training and test sets. Here are reported principal parameters:
    + *ratio* represent the split ratio. If it's a percentage it's used to define the training, if it's a number it represents the test set number of examples
    + the *mode* is important if one want to have an advanced control on how the splitting is performed
    + other parameters can be found in the documentation

* \texttt{fit(x, data = NULL, model = "default", task = "default", \dots)} -- it fits a supervised data mining model. Principal parameters are:
    + *x* is the formula of the model to fit, from the datasert *data*
    + *model* is the model to be used, there is a great variety of them
    + *task* is to select regression or classification for models that admit both
    + again, more parameters are available in the documentation
  
* \texttt{crossvaldata(x, data, theta.fit, theta.predict, ngroup = 10, model, task, \dots)} -- compute k-fold cross-validation for models. Main parameters are similar to *fit* function, and there are also:
    + *theta.fit* and *theta.predict* are the rminer function to be used respectively for fitting and prediction
    + *ngroup* represent the number of folds
    + again, more parameters are available in the documentation

## Evaluation
After having fitted the model one can proceed with the evaluation in order to understand the goodness of the model and eventually fix it. Main functions here are:

* \texttt{mmetric(y, metric, \dots)} -- used to get the metrics specified in the parameter *metric* about the model *y*
* \texttt{mgraph(y, graph, \dots)} -- used to print graphs about model accuracy: "RSC" and "REC" are common options for regression
* \texttt{mining(x, data = NULL, Runs = 1, method = NULL, model = "default", task = "default", \dots)} -- it's a powerful function that trains and tests a particular fit model under several *runs* and a given validation *method*


# Case Study: Life Expectancy
```{r include=FALSE}
library(ggplot2)
library(kknn)
library(ggpubr)
library(corrplot)
```
In this section it will be given a tour through the main functionalities of rminer by mean of a real life case study.

## The dataset
The dataset is about Life Expectancy and can be found in Kaggle (url in references). This dataset is available thanks to the World Health Organization who keeps track of the health status for all countries. It contains data about 193 countries from the year 2000 to 2015. All data column have a pretty self-explanatory name. For more details one can have a look into the official website from which the dataset has been taken.

For the purpose of this work a quick idea about the data can be achieved with the summary function in R, after lodaing it.
```r
lifeexp.df = read.csv("Life Expectancy Data.csv")
str(lifeexp.df)
summary(lifeexp.df) # here we can see NAs
```

```{r echo=FALSE}
# executed here to keep the output code clean
lifeexp.df = read.csv("Life Expectancy Data.csv")
str(lifeexp.df,width=87,strict.width="cut")
summary(lifeexp.df)
```

From here can be seen that there are 22 columns and that some of them have missing values that will need to be taken care of. The purpose is to use the *Life.expectancy* variable as dependent, and all the others as predictors.

An important note here about the package is that since the country variable is stored as a factor, using this dataset I've find out that rminer can't handle factors with more than 53 levels, so I transformed the country factor as a numerical.

```{r}
lifeexp.df$Country = as.numeric(lifeexp.df$Country)
```

### Imputation
Here I manage the missing value taking advantage of the \texttt{imputation()} function of the package.

```{r}
## IMPUTATION
# save column with missing values indexes
nacol = NULL
for (i in 1:ncol(lifeexp.df)) {
  if ( any(is.na(lifeexp.df[,i])) ) {
    nacol = c(nacol,i)
  }
}
    
# 1st method: case deletion
lifeexp.na.del = na.omit(lifeexp.df)

# 2nd method: imputation by mode
lifeexp.imp.mode = lifeexp.df
for (i in nacol) {
  lifeexp.imp.mode = imputation("value", lifeexp.imp.mode, i, 
                                Value=which.max(table(na.omit(lifeexp.df[,i]))))
}

# 3rd mode: imputation by hotdeck
lifeexp.imp.hotdeck = lifeexp.df
for (i in nacol) {
  lifeexp.imp.hotdeck = imputation("hotdeck", lifeexp.imp.hotdeck, i)
}
```

The first part is for convenience: I extract the column indexes that correspod to variables in which there are missing values. Then, just to check out for different methods, I tried to trivially remove missing values, and then I used the imputation function: firstly substituting NAs with the mode, and secondly then with the hotdeck method implemented inside the rminer package.

After this manupulation its possible to check the summary of the dataframe again to check the results (for example about the hotdeck method):

```{r}
summary(lifeexp.imp.hotdeck)
```

At the end, a brief comparison between the first four columns in which missing values have been managed (similar analysis can be checked for the others but requires more space) suggests that the hotdock method is a better --- and less naif --- compromise and tends to be more aligned with original data.

```{r}
plots = list()
j = 1
for (i in nacol[1:4]) {
    meth1=data.frame(v=lifeexp.na.del[[i]])
    meth2=data.frame(v=lifeexp.imp.mode[[i]])
    meth3=data.frame(v=lifeexp.imp.hotdeck[[i]])
    meth1$Method="NAs deleted"
    meth2$Method="Mode"
    meth3$Method="Hotdeck"
    all = rbind(meth1,meth2,meth3)
    plots[[j]] = ggplot(all,aes(v,fill=Method))+
      geom_density(alpha = 0.4)+
      xlab(colnames(lifeexp.df)[i])
    j = j+1
}
ggarrange(plotlist = plots, ncol=2, nrow=2, common.legend = TRUE, legend="bottom")

# we keep hotdeck version
lifeexp = lifeexp.imp.hotdeck
```

The final dataset is stored in a new variable with a more concise name for further model definition and evaluation.

Another quick insight that can be explored is to check the correlation matrix. Here we can see that there are not serius problems: some correlations are obvious considering variables meaning, and anyway those with high correlation are the first to check out later in case of poor model.

```{r fig.align='center', fig.height=7}
correlation = cor(within(lifeexp, rm("Status")))
corrplot(correlation, type="upper", method="circle")
```

## The model
As described above, the rminer package contains different models that can be used for regression analysis. *Random Forest* is only one of them. I've taken it as example of the package capabilities, but with small changes any other model can be used as same as this one.

In order to perform an analysis with a model it's important to have a training set to train the model, but it's necessary to have also a test set to evaluate the performance. Evaluating the model in the training set would lead to over-optimistic results.

For this purpose the package rminer lets the user to easily split the dataset into train and test sets, taking care of selecting random units in the right proportions. To this aim, I've trained the model in two different ways: one with the holdout method and one with 10-fold cross-validation.

Here's the code for model training:

```{r cache=TRUE}
# Holdout - Random Forest 
H = holdout(lifeexp$Life.expectancy, ratio=2/3, seed=42)
summary(H)
model1 = fit( Life.expectancy~., lifeexp[H$tr,], model="randomForest")

# 10-fold Cross-validation - Random Forest
model2 = crossvaldata(Life.expectancy~., lifeexp, fit, predict, ngroup=10, seed=42, 
                      model="randomForest", task="reg")
```

As can be seen, thanks to the rminer package, it's a very easy task to accomplish. After this, one can proceed with model evaluation.

## The Evaluation
The evaluation of the model is easy as the training. Using functions \texttt{mgraph} and \texttt{mmetric} can be printed the *Regression Scatter Plot* and all the metrics.

```{r cache=TRUE}
# Holdout
pred1 = predict(model1, lifeexp[H$ts,]) # get predictions on test set (new data)
target1 = lifeexp[H$ts,]$Life.expectancy
mgraph(target1, pred1, graph="RSC", Grid=10, main="Random Forest - Holdout 1/3")
mmetric(target1, pred1, metric="ALL")

# 10-fold cross-validation
pred2 = model2$cv.fit # k-fold predictions on full dataset
mgraph(lifeexp$Life.expectancy, pred2, graph="RSC", Grid=10, 
       main="Random Forest - 10-fold Cross Validation")
mmetric(lifeexp$Life.expectancy, pred2, metric="ALL")
```

A further very useful function that can be used is the \texttt{mining} function. It lets the user to execute several fit and predict runs with a single line of code. After mining, all the metrics are available for examination (note that since there can be a huge number of models, the fitted models are not stored).

```{r cache=TRUE}
# mining for randomForest, external 3-fold, 20 Runs (=60 fitted models)
model3.mining = mining(Life.expectancy~., lifeexp, 
                       model="randomForest", method=c("kfold",3,42), Runs=20)
m=mmetric(model3.mining, metric=c("MAE","RMSE","R2"))
print(m) # show metrics for each run
```

Finally one can be interest in comparing the mining of a model with the mining of another model, and this can be achieved with this commands:

```{r cache=TRUE}
# mining for standard multiple linear regression
model4.mining = mining(Life.expectancy~., lifeexp, 
                       model="mr", method=c("kfold",3,42), Runs=20)

L=vector("list",2)
L[[1]]=model3.mining
L[[2]]=model4.mining
mgraph(L, graph="REC", leg=c("randomForest","mr"), main="REC curve", xval=10)
```

In this case the Random Forest model is compared with a standard multiple linear regression model. They are compared with REC curves. The Regression Error Characteristic (REC) curve is the corresponding of the ROC curve for regression. It plots the error tolerance on the x-axis versus the percentage of points predicted within the tolerance on the y-axis. More information about the REC curve can be found in [@bi2003regression].

From the REC curve we can see the two models performance and see the advantage of using a more complex model with the same ease as the standard linear regression model. Of course this is not a detailed comparison, and further improvements in the linar model can be for sure achieved, but the aim here is to place emphasis on the wide spread of tools offered by rminer.

# Conclusions
Eventually, from this work it's evident that the package rminer is a good tool to perform regression analysis. With its small set of functions --- but with a wide spread of options and parameters --- can be useful to someone who want to do an overall analysis, but also to someone that want a finer granularity for personalization in model hyperparameters. In this brief tour of the package I didn't analyze the details about hyperparameters tuning, but with a quick look into the documentation one can face up this task too as easily as what done here. Must be said also that for an advanced user with very specific requirements, this package can be a bit limiting, but anyway, it's a very good starting point for a regression analysis.

\pagebreak

# References